import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from sklearn.model_selection import train_test_split
from dotenv import load_dotenv

# Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()


# PDF'yi yÃ¼kle
base_dir = os.path.dirname(os.path.abspath(__file__))
pdf_path = os.path.join(base_dir, "..", "data", "gerekceli_anayasa.pdf")
pdf_path = os.path.abspath(pdf_path)
loader = PyPDFLoader(pdf_path)
data = loader.load()

# Metni parÃ§alara bÃ¶l
text_splitter = RecursiveCharacterTextSplitter(chunk_size=800)
docs = text_splitter.split_documents(data)

# EÄŸitim ve test verisi olarak ayÄ±r
train_docs, test_docs = train_test_split(docs, test_size=0.2, random_state=42)

# VektÃ¶r veritabanÄ± ve retriever
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
vectorstore = Chroma.from_documents(
    documents=train_docs,
    embedding=embeddings,
    persist_directory="../../chroma_db_gemini"
)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 10})

# LLM modeli
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",
    temperature=0.3,
    max_tokens=500
)

# Sistem promptu
system_prompt = (
    "Sen TÃ¼rkiye'deki yasalarÄ±n hepsini bilen, insanlarÄ±n yasalar hakkÄ±ndaki sorularÄ±nÄ± doÄŸru bir ÅŸekilde cevaplayan cana yakÄ±n bir asistansÄ±n. "
    "GÃ¶revin, kÄ±sa ve Ã¶z bir ÅŸekilde verilen sorularÄ± cevaplamak. "
    "Sadece TÃ¼rkiye AnayasasÄ± hakkÄ±nda konuÅŸ, baÅŸka bir Ã¼lkenin yasalarÄ± hakkÄ±nda konuÅŸma. "
    "YanÄ±tlarÄ±n TÃ¼rkÃ§e olsun ve aÃ§Ä±klamalarÄ±nÄ± emojilerle zenginleÅŸtir. ğŸ“šâš–ï¸\n\n"
    "{context}"
)

# Prompt ÅŸablonu
prompt_template = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("human", "{input}")
])



