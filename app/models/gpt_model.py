import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from dotenv import load_dotenv
from sklearn.model_selection import train_test_split

# Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

# PDF'yi yÃ¼kle
base_dir = os.path.dirname(os.path.abspath(__file__))
pdf_path = os.path.join(base_dir, "..", "data", "gerekceli_anayasa.pdf")
pdf_path = os.path.abspath(pdf_path)
loader = PyPDFLoader(pdf_path)
data = loader.load()

# Metni parÃ§alara bÃ¶l
text_splitter = RecursiveCharacterTextSplitter(chunk_size=800)
docs = text_splitter.split_documents(data)

# EÄŸitim ve test verisi olarak ayÄ±r
train_docs, test_docs = train_test_split(docs, test_size=0.2, random_state=42)

# VektÃ¶r veritabanÄ± oluÅŸtur
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
vectorstore = Chroma.from_documents(
    documents=train_docs,
    embedding=embeddings,
    persist_directory="../../chroma_db_gpt"
)

# Retriever oluÅŸtur
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 10})

# Chat LLM modeli
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.3,
    max_tokens=500
)

# Sistem rolÃ¼ promptu
system_prompt = (
    "Sen TÃ¼rkiye'deki yasalarÄ±n hepsini bilen, insanlarÄ±n yasalar hakkÄ±ndaki sorularÄ±nÄ± doÄŸru bir ÅŸekilde cevaplayan cana yakÄ±n bir asistansÄ±n. "
    "GÃ¶revin, kÄ±sa ve Ã¶z bir ÅŸekilde verilen sorularÄ± cevaplamak. "
    "Sadece TÃ¼rkiye AnayasasÄ± hakkÄ±nda konuÅŸ, baÅŸka bir Ã¼lkenin yasalarÄ± hakkÄ±nda konuÅŸma. "
    "YanÄ±tlarÄ±n TÃ¼rkÃ§e olsun ve aÃ§Ä±klamalarÄ±nÄ± emojilerle zenginleÅŸtir. ğŸ“šâš–ï¸\n\n"
    "{context}"
)

# Prompt ÅŸablonu
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}")
    ]
)

